{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./resources/ratings_train.txt', delimiter='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['document'].values\n",
    "y_train = df_train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./resources/ratings_test.txt', delimiter='\\t', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['document'].values\n",
    "y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 [75173 74827]\n",
      "50000 [24827 25173]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), np.bincount(y_train))\n",
    "print(len(X_test), np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "['사이', '몬페', '그', '의', '익살스런', '연기', '가', '돋보였던', '영화', '!', '스파이더맨', '에서', '늙어', '보이기만', '했던', '커스틴', '던스트', '가', '너무나도', '이뻐', '보였다']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "print(X_train[4])\n",
    "print(okt.morphs(X_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer는 기본적으로 공백을 기준으로 토큰은 구분\n",
    "# tokenizer 매개변수에 토큰화를 위한 사용자 정의 함수를 전달할 수 있음\n",
    "# okt.morphs 메서드를 전달하면 형태소 분석을 통해 토큰화 수행할 수 있음\n",
    "# tokenizer 매개변수를 사용할 때 패턴을 token_patter=None으로 지정하여 token_pattern 매개변수가 사용되지 않는다는 경고 메시지 나오지 않게\n",
    "# TifdfVectorizer ngram_range=(1, 2)로 설정하여 유니그램과 바이그램을 사용하고 min_df=3으로 지정하여 3회 미만으로 등장하는 토큰은 무시.\n",
    "# max_df=0.9로 두어 가장 많이 등장하는 상위 10% 토큰도 무시\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                        min_df=3,\n",
    "                        max_df=0.9,\n",
    "                        tokenizer=okt.morphs,\n",
    "                        token_pattern=None)\n",
    "tfidf.fit(X_train)\n",
    "X_train_okt = tfidf.transform(X_train)\n",
    "X_test_okt = tfidf.transform(X_test)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=SGDClassifier(loss='log', random_state=1),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f494647ac70>},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGDClassifier 클래스를 사용해서 감성 분류 문제 해결\n",
    "# SGDClassfier의 매개변수는 규제를 위한 alpha 매개변수.\n",
    "# RandomizedSearchCV 클래스를 사용하기 위해 loguniform 함수로 탐색 범위 지정.\n",
    "# SGDClassifier의 손실 함수로 로지스틱 손실('log')을 사용하지만 다른 손실 함수를 매개변수 탐색에 포함할 수 있음.\n",
    "# 총 반복 회수(n_iter)는 50회로 지정\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils.fixes import loguniform\n",
    "sgd = SGDClassifier(loss='log', random_state=1)\n",
    "param_dist = {'alpha': loguniform(0.0001, 100.0)}\n",
    "rsv_okt = RandomizedSearchCV(estimator=sgd,\n",
    "                            param_distributions=param_dist,\n",
    "                            n_iter=50,\n",
    "                            random_state=1,\n",
    "                            verbose=1,\n",
    "                            n_jobs=4)\n",
    "rsv_okt.fit(X_train_okt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8251533333333334\n",
      "{'alpha': 0.0001001581395585897}\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 탐색으로 찾은 최상의 점수와 매개변수 값\n",
    "print(rsv_okt.best_score_)\n",
    "print(rsv_okt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터셋 X_test_okt에서 점수 확인\n",
    "rsv_okt.score(X_test_okt, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화!스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
     ]
    }
   ],
   "source": [
    "# soynlp 세 개의 토큰화 클래스 제공 LTokenizer, MaxScoreTokenizer, RegexTokenizer\n",
    "# https://github.com/lovit/soynlp\n",
    "# 띄어쓰기가 잘 되어 있다면 LTokenizer\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "lto = LTokenizer()      # 공백으로만 토큰화 수행\n",
    "print(lto.tokenize(X_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.308 Gbse memory 1.261 Gb\n",
      "all cohesion probabilities was computed. # words = 85683\n",
      "all branching entropies was computed # words = 101540\n",
      "all accessor variety was computed # words = 101540\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "word_ext = WordExtractor()\n",
    "word_ext.train(X_train)\n",
    "scores = word_ext.word_scores()\n",
    "# 반환된 scores 객체는 단어마다 결합 점수(cohesion score)와 브랭칭 엔트로피(branching entropy)를 가진 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사이', '몬페그의', '익살스', '런', '연기', '가', '돋보', '였던', '영화', '!스파이더맨에서', '늙어', '보이기만', '했던', '커스틴', '던스트가', '너무', '나도', '이뻐', '보였다']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "score_dict = {key: scores[key].cohesion_forward * math.exp(scores[key].right_branching_entropy) for key in scores}\n",
    "lto = LTokenizer(scores=score_dict)\n",
    "print(lto.tokenize(X_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=SGDClassifier(loss='log', random_state=1),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f494647ac70>},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                        min_df=3,\n",
    "                        max_df=.9,\n",
    "                        tokenizer=lto.tokenize,\n",
    "                        token_pattern=None)\n",
    "tfidf.fit(X_train)\n",
    "X_train_soy = tfidf.transform(X_train)\n",
    "X_test_soy = tfidf.transform(X_test)\n",
    "rsv_soy = RandomizedSearchCV(estimator=sgd,\n",
    "                            param_distributions=param_dist,\n",
    "                            n_iter=50,\n",
    "                            random_state=1,\n",
    "                            verbose=1,\n",
    "                            n_jobs=4)\n",
    "rsv_soy.fit(X_train_soy, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8141066666666665\n",
      "{'alpha': 0.0001001581395585897}\n"
     ]
    }
   ],
   "source": [
    "print(rsv_soy.best_score_)\n",
    "print(rsv_soy.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsv_soy.score(X_test_soy, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e30e104fa17c260866f45c2015a884099ba44245f47b80d68b248bea09254b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
