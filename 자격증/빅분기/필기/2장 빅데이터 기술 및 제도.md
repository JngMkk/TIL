# 2장 빅데이터 기술 및 제도

> 2022 이기적 빅데이터분석기사 필기편



## 목차

[TOC]



## 1. 빅데이터 플랫폼

> 빅데이터 플랫폼은 **<u>빅데이터 수집부터 저장, 처리, 분석 등 전 과정을 통합 제공</u>**하여 그 기술들을 잘 사용할 수 있도록 준비된 환경
>
> 빅데이터를 분석 또는 활용하는데 필요한 필수적인 것, 빅데이터 기술의 집합체

### 1) 빅데이터 플랫폼의 등장배경

- 비즈니스 요구사항 변화
  - 빠른 의사결정 속도보다 장기적이고 정략적인 접근 필요
  - 초저가의 대규모 프로세싱과 클라우드 컴퓨팅 기반의 분석 황경 등장
- 데이터 규모와 처리 복잡도 증가
  - 다양한 형태의 데이터 수집과 복잡한 로직을 이용한 대용량 처리 필요
  - 분산 처리가 불가피하며 이를 제어할 수 있는 고도의 기술 필요
- 데이터 구조의 변화와 신속성 요구
  - SNS 데이터나 로그 파일, 스트림 데이터 등 비정형 데이터의 비중과 실시간 처리에 대한 요구가 높아짐
  - 약한 관계형 스키마나 반정형 데이터와 같은 정형적이지 않은 데이터 증가
- 데이터 분석 유연성 증대
  - 기존의 통계적 분석방법과 같이 정해진 절차와 과정을 따르지 않아도 분석 목적에 맞게 유연한 분석 가능
  - 인공지능 기술의 발전으로 다양한 방법론을 통해 텍스트, 음성, 이미지, 동영상 등 다양한 요소들 분석 가능

### 2) 빅데이터 플랫폼의 기능

> 빅데이터를 처리하는 과정에서 부하 발생은 불가피
>
> 빅데이터 플랫폼은 이러한 부하들을 기술적인 요소들을 결합하여 해소

- 컴퓨팅 부하 발생 : 빅데이터를 처리하고자 할 때 연산과정에서 CPU, GPU, 메모리 등을 사용
  - 빅데이터 플랫폼을 통한 CPU 성능 향상 및 클러스터에서의 효과적인 자원 할당을 통해 부하 제어
- 저장 부하 발생 : 빅데이터 처리 과정의 입력 데이터, 중간 가공 데이터, 출력 데이터 등 여러 단계에서 부하 발생
  - 빅데이터 플랫폼을 통한 파일 시스템 개선, 메모리와 파일 시스템의 효과적인 사용 및 데이터베이스 성능 향상으로 제어
- 네트워크 부하 발생 : 빅데이터를 처리하는 과정에서 분산처리를 할 때 노드 간의 통신 과정에서 부하 발생
  - 빅데이터 플랫폼을 통한 대역폭의 효과적 분배 및 네트워크상에서 최단거리에 위치한 노드 탐색으로 제어

### 3) 빅데이터 플랫폼의 조건

> 빅데이터 플랫폼은 서비스 사용자와 제공자 어느 한쪽에 치우쳐서는 안되며 모두가 만족할 수 있는 환경을 제공하여야 함

- 서비스 사용자 측면에서의 체크리스트
  - 주어진 문제를 해결하기에 충분한 요소들을 제공하는 환경인가?
  - 편리한 사용자 인터페이스(UI)를 제공하는가?
- 서비스 제공자 측면에서의 체크리스트
  - 성능적인 문제가 발생하지 않도록 충분한 괄리 기능을 제공하는가?
  - 사용자 접속 및 인증을 관리할 수 있는 기능을 제공하는가?
  - 효율적인 운영을 위한 자원 관리 기능을 제공하는가?
  - 서비스 품질 관리를 위한 각종 지표들을 충분히 제공하는가?
  - 안전한 서비스 제공을 위한 보안적인 요소들을 갖추고 있는가?
  - 플랫폼 도입을 통해 비용 절감을 이룰 수 있는가?

### 4) 빅데이터 플랫폼의 구조

- 소프트웨어 계층

  > 빅데이터 애플리케이션을 구성하며 데이터 처리 및 분석과 이를 위한 데이터 수집, 정제를 함

![2-1](https://user-images.githubusercontent.com/87686562/147850744-a9228b59-8e7c-471e-984c-8a99013948e9.PNG)

- 플랫폼 계층

  > 빅데이터 애플리케이션을 실행하기 위한 플랫폼을 제공하며, 작업 스케줄링이나 데이터 및 자원 할당과 관리, 프로파일링 등 수행

![2-2](https://user-images.githubusercontent.com/87686562/147850745-31960d32-5469-4669-87c9-59ac9fcdfef2.PNG)

- 인프라스트럭처 계층

  > 자원 배치와 스토리지 관리, 노드 및 네트워크 관리 등을 통해 빅데이터 처리와 분석에 필요한 자원 제공

![2-3](https://user-images.githubusercontent.com/87686562/147850746-5d92cabf-d09a-46ca-b5d7-e25333da6e19.PNG)



## 2. 빅데이터 처리기술

### 1) 빅데이터 처리과정과 요소 기술

- 빅데이터 처리 과정

  `데이터(생성)` - `수집` - `저장(공유)` - `처리` - `분석` - `시각화`

  - 생성
    - 데이터베이스나 파일 관리 시스템과 같은 내부 데이터가 있음
    - 인터넷으로 연결된 외부로부터 생성된 파일이나 데이터가 있음
  - 수집
    - 크롤링을 통해 데이터 원천으로부터 데이터를 검색하여 수집
    - ETL을 통해 소스 데이터로부터 추출, 변환, 적재
    - 단순한 수집이 아니라 검색 및 수집, 변환 과정을 모두 포함
    - 로그 수집기나, 센서 네트워크 및 Open API 등을 활용할 수 있음
  - 저장(공유)
    - 저렴한 비용으로 데이터를 쉽고 빠르게 많이 저장
    - 정형 데이터뿐만 아니라 반정형, 비정형 데이터도 포함
    - 병렬 DBMS나 하둡, NoSQL 등 다양한 기술을 사용할 수 있음
    - 시스템 간의 데이터를 서로 공유할 수 있음
  - 처리
    - 데이터를 효과적으로 처리하는 기술이 필요한 단계
    - 분산 병렬 및 인 메모리 방식으로 실시간 처리
    - 대표적으로 하둡의 맵리듀스를 활용할 수 있음
  - 분석
    - 데이터를 신속하고 정확하게 분석하여 비즈니스에 기여
    - 특정 분야 및 목적의 특성에 맞는 분석 기법 선택이 중요
    - 통계분석, 데이터 마이닝, 텍스트 마이닝, 기계학습 방법 등이 있음
  - 시각화
    - 처리 및 분석 결과를 표, 그래프 등을 이용해 쉽게 표현하고 탐색이나 해석에 활용
    - 정보 시각화 기술, 시각화 도구, 편집 기술, 실시간 자료 시각화 기술로 구성되어 있음

### 2) 빅데이터 수집

- 크롤링

  - 무수히 많은 컴퓨터에 분산 저장되어 있는 문서를 수집하여 검색 대상의 색인으로 포함시키는 기술

- 로그 수집기

  - 조직 내부에 있는 웹 서버나 시스템의 로그를 수집하는 소프트웨어

- 센서 네트워크

  - 유비쿼터스 컴퓨팅 구현을 초경량 저전력의 많은 센서들로 구성된 유무선 네트워크

- RSS Reader / Open API

  - 데이터의 생산, 공유, 참여할 수 있는 환경인 웹 2.0을 구현하는 기술

- ETL 프로세스(Extract, Transform, Load)

  - 데이터의 추출, 변환, 적재의 약어로, **<u>다양한 원천 데이터를 취합해 추출하고 공통된 형식으로 변환하여 적재하는 과정</u>**

  | 과정                    | 설명                                                         |
  | ----------------------- | ------------------------------------------------------------ |
  | 데이터 추출 (Extract)   | - 원천 데이터로부터 적재하고자 하는 데이터를 추출            |
  | 데이터 변환 (Transform) | - 추출한 데이터를 변환하고 균질화하며 정제<br />- 정제한 데이터를 적재하고자 하는 데이터 웨어하우스 구조에 맞게 변환<br />- 통합하는 제약 조건 및 비즈니스 규칙에 따라 필터링이나 확인 작업 |
  | 데이터 적재 (Load)      | - 변환된 데이터를 데이터 웨어하우스에 적재                   |

### 3) 빅데이터 저장

- **NoSQL(Not-only SQL)**

  > 전통적인 관계형 데이터베이스와는 다르게 데이터 모델을 단순화하여 설계된 비관계형 데이터베이스
  >
  > SQL을 사용하지 않는 DBMS와 데이터 저장장치

  - 기존의 RDBMS 트랜잭션 속성인 원자성, 일관성, 독립성, 지속성을 포기
  - 데이터 업데이트가 즉각적으로 가능한 데이터 저장소
  - Clouddata, Hbase, Cassandra, MongoDB 등이 대표적

- 공유 데이터 시스템(Shared-data System)

  - 일관성, 가용성, 분할 내성 중에서 최대 두 개의 속성만 보유할 수 있음 (CAP 이론)
  - 분할 내성을 취하고 일관성과 가용성 중 하나를 포기하여 일관성과 가용성을 모두 취하는 기존 RDBMS보다 높은 성능과 확장성 제공

- 병령 데이터베이스 관리 시스템(Parallel Database Management System)

  > 다수의 마이크로프로세서를 사용하여 여러 디스크에 질의, 갱신, 입출력 등 데이터베이스 처리를 동시에 수행하는 시스템

  - 확장성을 제공하기 위해 작은 다위의 동작으로 트랜잭션 적용이 필요
  - VoltDB, SAP HANA, Verica, Greenplum, Netezza가 대표적

- 분산 파일 시스템

  > 네트워크로 공유하는 여러 호스트의 파일에 접근할 수 있는 파일 시스템

  - 데이터를 분산하여 저장하면 데이터 추출 및 가공 시 빠르게 처리할 수 있음
  - GFS(Google File System), HDFS(Hadoop Distributed File System), 아마존 S3 파일 시스템이 대표적

- 네트워크 저장 시스템

  > 이기종 데이터 저장 장치를 하나의 데이터 서버에 연결하여 총괄적으로 데이터를 저장 및 관리하는 시스템

  - SAN(Storage Area Network), NAS(Network Attached Storage)가 대표적

### 4) 빅데이터 처리

- 분산 시스템과 병렬 시스템

  - 용어는 구분되어 사용되기도 하지만 서로 중첩되는 부분이 많아 실제 시스템에서도 이 둘을 명확히 구분하기 어려움
  - 두 개념을 아우르는 분산 병렬 컴퓨팅이라는 용어를 사용
  - 분산 시스템
    - 네트워크상에 분산되어 있는 컴퓨터를 단일 시스템인 것처럼 구동하는 기술
    - 분산 시스템에 속한 각 노드는 독립된 시스템
    - 독립 컴퓨터의 집합으로 만들었으나 마치 단일 시스템인 것처럼 수행되어야 함
  - 병렬 시스템
    - 문제 해결을 위해 CPU 등의 자원을 데이터 버스나 지역 통신 시스템 등으로 연결하여 구동하는 기술
    - 분할된 작업을 동시에 처리하여 계산 속도를 빠르게 함

- 분산 병렬 컴퓨팅

  > 다수의 독립된 컴퓨팅 자원을 네트워크상에 연결하여 이를 제어하는 미들웨어를 이용해 하나의 시스템으로 동작하게 하는 기술

  - 분산 병력 컴퓨팅 시 고려사항

    | 문제                                                         | 설명                                                         |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | 전체 작업의 배분 문제                                        | - 전체 작업을 잘 쪼개어 여러 개의 작은 작업으로 나눠야 함    |
    | 각 프로세서에서 계산된<br />중간 결과물을<br />프로세서 간 주고받는 문제 | - 효율적인 통신은 성능과 직결<br />- 보통 단일 시스템은 전체 작업을 노드의 수만큼 균등하게 나눔<br />- 이종 시스템은 컴퓨팅 능력에 따라 전체 작업을 배분<br />- 노드 간의 통신을 최소화하는 기법 등이 반영되면 자원을 좀 더 효율적으로 사용할 수 있어 성능 향상에 도움이 됨 |
    | 서로 다른 프로세서 간<br />동기화 문제                       | - 데이터 병렬 처리에서 동기적 방법을 사용할 경우 프로세서는 특정 계산이 끝나거나 특정 데이터를 넘겨받을 때까지 반드시 대기하여야 함<br />- 동기적 방법의 경우 송신자는 수진자에게서 데이터를 받았다는 응답이 올 때까지 대기하여야 함<br />- 비동기적 방법에서는 결과 메시지를 보낸 즉시 다음 작업을 계속할 수 있음<br />- 비동기적 방법의 경우 프로세서는 기다릴 필요가 없지만, 계산과정이 적합한지는 확인해야 함 |

- 하둡

  > <u>**분산 처리 환경에서 대용량 데이터 처리 및 분석을 지원하는 오픈 소스 소프트웨어 프레임워크**</u>

  - 하둡 분산파일시스템인 HDFS와 분산칼럼기반 데이터베이스인 Hbase, 분산 컴퓨팅 지원 프레임워크인 맵리듀스로 구성
  - 분산파일시스템을 통해 수 천대의 장비에 대용량 파일을 나누어 저장할 수 있는 기능을 제공
    - 분산파일시스템에 저장된 대용량의 데이터들을 맵리듀스를 이용하여 실시간으로 처리 및 분석 가능
  - 하둡의 부족한 기능을 보완하는 하둡 에코시스템이 등장하여 다양한 솔루션을 제공

- 아파치 스파크

  > 실시간 분산형 컴퓨팅 플랫폼으로 In - Memory 방식으로 처리를 하며 하둡보다 처리속도가 빠름

  - 스칼라 언어로 개발되었지만 스칼라뿐만 아니라 Java, R, Python을 지원

- 맵리듀스

  > 구글에서 개발한 방대한 양의 데이터를 신속하게 처리하는 프로그래밍 모델로 **<u>효과적인 병렬 및 분산 처리를 지원</u>**
  >
  > 분산 병렬 데이터 처리 기술의 표준

  - 런타임에서의 입력 데이터 분할, 작업 스케줄링, 노드 고장, 노드 간의 데이터 전송 작업이 맵리듀스 처리 성능에 많은 영향을 미침
  - 맵리듀스 처리단계
    - 1단계 : 입력 데이터를 읽고 분할
    - 2단계 : 분할된 데이터를 할당해 맵 작업을 수행한 후, 그 결과인 중간 데이터를 통합 및 재분할
    - 3단계 : 통합 및 재분할된 중간 데이터를 셔플
    - 4단계 : 셔플된 중간 데이터를 이용해 리듀스 작업 수행
    - 5단계 : 출력 데이터를 생성, 맵리듀스 처리를 종료


<img src="https://user-images.githubusercontent.com/87686562/147851354-40fe860c-4123-45ff-9d7c-c92e4c8f24be.jpg" alt="2-4" style="zoom:15%;" />



### 5) 빅데이터 분석

- 데이터 분석 방법의 분류

  - 탐구 요인 분석(EFA : Exploratory Factor Analysis)
    - 데이터 간 상호 관계를 파악하여 데이터를 분석하는 방법
  - 확인 요인 분석(CFA : Confirmatory Factor Analysis)
    - 관찰된 변수들의 집합 요소 구조를 파악하기 위한 통계적 기법을 통해 데이터를 분석하는 방법

- 데이터 분석 방법

  | 구분                  | 내용                                                         |
  | --------------------- | ------------------------------------------------------------ |
  | 분류 (Classification) | - 미리 알려진 클래스들로 구분되는 학습 데이터셋을 학습시켜 새로 추가되는 데이터가 속할 만한 데이터 셋을 찾는 지도학습 방법 |
  | 군집화(Clustering)    | - 특성이 비슷한 데이터를 하나의 그룹으로 분류하는 방법, 분류와 달리 학습 데이터셋을 이용하지 않는 비지도학습 방법 |
  | 기계학습(ML)          | - 인공지능 분야에서 인간의 학습을 모델링한 방법<br />- 의사결정트리 등 기호적 학습과 신경망이나 유전 알고리즘 등 비기호적 학습<br />베이지안 또는 은닉 마코프 등 확률적 학습 등의 기법 |
  | 텍스트 마이닝         | - 자연어 처리 기술을 이용해 인간의 언어로 쓰인 비정형 텍스트에서 유용한 정보를 추출하거나<br /> 다른 데이터와의 연관성 파악하기 위한 방법 |
  | 웹 마이닝             | - 인터넷을 통해 수집한 정보를 데이터 마이닝 방법으로 분석하는 응용분야 |
  | 오피니언 마이닝       | - 온라인의 다양한 뉴스와 소셜 미디어 코멘트 또는 사용자가 만든 콘텐츠에서 표현된 의견을 추출, 분류, 이해하는 응용분야 |
  | 리얼리티 마이닝       | - 휴대폰 등 기기를 사용하여 인간관계와 행동 양태 등을 추론하는 응용분야<br />- 통화량, 통화 위치, 통화 상태, 통화 대상, 통화 내용 등을 분석하여 사용자의 인간관계나 행동 특성을 찾아냄 |
  | 소셜 네트워크 분석    | - 수학의 그래프 이론을 바탕으로 소셜 네트워크 서비스에서 네트워크 연결 구조와 강도를 분석하여<br /> 사용자의 명성 및 영향력을 측정하는 방법 |
  | 감성 분석             | - 문장의 의미를 파악하여 글의 내용에 긍정 또는 부정을 분류하거나 만족 또는 불만족 강도를 지수화하는 방법<br />- 도출된 지수를 이용하여 고객의 감성 트렌드를 시계열로 분석하고<br /> 고객의 감성 변화에 기업들이 신속하게 대응 및 부정적인 의견의 확산을 방지하는 데 활용할 수 있음 |



## 3. 빅데이터와 인공지능

### 1) 인공지능

- 인공지능의 정의

  - 인공지능은 기계를 지능화하는 노력이며, 지능화란 객체가 환경에서 적절히, 그리고 예지력을 갖고 작동하도록 하는 것
  - 인공지능은 합리적 행동 수행자이며, 어떤 행동이 최적의 결과를 낳을 수 있또록 하는 의사결정 능력을 갖춘 에이전트를 구축하는 것
  - 인공지능은 설정한 목표를 극대화하는 행동을 제시하는 의사결정 로직

- 인공지능과 기계학습 및 딥러닝의 관계

  > 인공지능을 논할 때 기계학습과 딥러닝을 혼재하여 사용함

  - 인공지능은 사람이 생각하고 판단하는 사고 구조를 구축하려는 전반적인 노력
  - 기계학습은 인공지능의 연구 분야 중 하나로 인간의 학습 능력과 같은 기능을 축적된 데이터를 활용하여 실현하고자 하는 기술 및 방법
  - 딥러닝은 기계학습 방법 중 하나로 컴퓨터가 많은 데이터를 이용해 사람처럼 스스로 학습할 수 있도록 인경신경망 등의 기술을 이용한 기법
    - 딥러닝 : 전신인 신경망의 여러 단점을 극복해 유연성과 확장성 확보

- 딥러닝의 특징

  - 딥러닝은 제프리 힌튼의 노력으로 함수추정 방법으로써의 신경망 관점에서 정보를 압축, 가공, 재현하는 알고리즘으로 일반화
  - 깊은 구조에 의해 엄청난 양의 데이터를 학습할 수 있는 특징을 갖고 있음
    - 딥러닝의 학습을 위한 데이터의 확보는 곧 우수한 인공지능 개발과 깊은 관련성 있음

- 기계학습 종류

  | 종류                                       | 내용                                                         |
  | ------------------------------------------ | ------------------------------------------------------------ |
  | 지도학습<br />(Supervised Learning)        | - 학습 데이터로부터 하나의 함수를 유추해내기 위한 방법<br />- 지도 학습기가 하는 직업은 훈련 데이터로부터 주어진 데이터에 대해 예측하고자 하는 값을 올바르게 추측해 내는 것 |
  | 비지도학습<br />(Unspervised Learning)     | - 데이터가 어떻게 구성되었는지를 알아내는 문제의 범주에 속함<br />- 지도학습 혹은 강화학습과는 달리 입력값에 대한 목표치가 주어지지 않음<br />- 통계의 밀도 추정과 깊은 연관이 있으며, 데이터의 주요 특징을 요약하고 설명할 수 있음 |
  | 준지도학습<br />(Semi-supervised Learning) | - 목표값이 표시된 데이터와 표시되지 않은 데이터를 모두 학습에 사용하는 것<br />- 많은 기계학습 연구자들이 목표값이 없는 데이터에 적은 양의 목표값을 포함한 데이터를 사용할 경우<br /> 학습 정확도에 있어서 상당히 좋아짐을 확인함 |
  | 강화학습<br />(Reinforcement Learning)     | - 행동심리학에서 영감을 받았으며, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 순서를 선택하는 방법<br />- 강화학습의 초점은 학습 과정에서의 성능, 이는 탐색과 이용의 균형을 맞춤으로써 제고됨 |

- 기계학습 방법에 따른 인공지능 응용분야

<img src="https://user-images.githubusercontent.com/87686562/147873425-ad080f37-4ea2-4452-a7bc-653aef16e40a.PNG" alt="2-5" style="zoom:100%;" />

### 2) 인공지능 데이터 학습의 진화

- 전이학습(Transfer Learning)

  > 인간의 응용력과 같이 유사 분야에 학습된 딥러닝 모형을 다른 문제를 해결하기 위해 사용하고자 할 때
  >
  > 적은 양의 데이터로도 좋은 결과를 얻을 수 있다.

  - 주로 이미지, 언어, 텍스트 인식과 같이 지도학습 중 분류모형인 인식 문제에 활용 가능함
    - 인식 문제의 경우 데이터 표준화가 가능하여 사전학습모형 입력형식에 맞출 수 있음

- 전이학습 기반 사전학습모형(Pre-trained Model)

  > 학습 데이터에 의한 인지능력을 갖춘 딥러닝 모형에 추가적인 데이터를 학습시키는 방식

  - 데이터 학습량에 따라 점차 발전하는 것도 중요하지만, 응용력을 갖추는 것 또한 필수적
  - 상대적으로 적은 양의 데이터로도 제한된 문제에 인공지능 적용이 가능
    - 이미 학습된 사전학습모형도 데이터를 함축한 초보적 인공지능으로서 충분한 가치를 지닌 새로운 의미의 데이터라 할 수 있음

- BERT(Bidirectional Encoder Representations from Transformers)

  > 2018년 구글에서 발표한 언어인식 사전학습모형.
  >
  > 확보된 언어 데이터의 추가 학습을 통한 신속한 학습이 가능

  - 다층의 임베딩 구조를 통해 1억2천 개가 넘는 파라미터로 구성된 획기적인 모형
  - 256개까지의 문자가 입력되어 768차원 숙자 벡터가 생성되는 방식
  - 언어 인식뿐 아니라 번역, 챗봇의 Q&A 엔진으로 활용 가능

### 3) 빅데이터와 인공지능의 관계

- 인공지능을 위한 학습 데이터 확보

  - 학습 데이터 측면을 고려한 **<u>양질의 데이터 확보는 결국 성공적인 인공지능 구현과 직결됨</u>**
  - 딥러닝은 깊은 구조를 통해 무한한 모수 추정이 필요한 만큼 많은 양의 데이터가 필요
  - 인공지능 학습에 활용될 수 있는 데이터로 가공이 필요하며, 학습의 가이드를 제공해 주는 애노테이션 작업이 필수적
    - 애노테이션 : 데이터상의 주석 작업으로 딥러닝과 같은 학습 알고리즘이 무엇을 학습하여야 하는지 알려주는 표식 작업

- 학습 데이터의 애노테이션 작업

  > 많은 데이터 확보 후 애노테이션을 통해 학습이 가능한 데이터로 가공하는 작업이 필요

  - 작업의 특성상 많은 수작업이 동반되며, 이로 인해 인공지능 사업은 노동집약적이라는 인식을 만들어 냄

  <img src="https://user-images.githubusercontent.com/87686562/147874472-6e2e37e2-edc6-433e-9cc8-451bfffd9a38.jpg" alt="2-6" style="zoom:20%;" />

  

- 애노테이션 작업을 위한 도구로써의 인공지능
  - 인공지능 시장이 확장되며 애노테이션 작업을 전문으로 하는 기업의 수가 증가하였다
    - 경쟁으로 인해 학습용 데이터에 대한 보안 및 애노테이션 결과에 대한 품질 요구수준이 높아짐
    - 기업들은 데이터 업로드 및 애노테이션 도구, 작업 모니터링을 위한 플랫폼을 제공하기 시작함
  - 현재 자동으로 애노테이션을 수행해 주는 인공지능 기반의 애노테이션 도구를 제공하는 서비스로 진화 중

### 4) 인공지능의 기술동향

- 기계학습 프레임워크 보급 확대

  > 인터페이스와 라이브러리, 툴 등 기계학습 모형 개발을 쉽고 빠르게 하도록 지원하는 기반

  - 구글브레인이 개발한 텐서플로우는 파이썬 기반 딥러닝 라이브러리로 여러 CPU 및 GPU와 플랫폼에서 사용 가능
  - 케라스는 딥러닝 신경망 구축을 위한 단순화된 인터페이스를 가진 라이브러리. 몇 줄의 코드만으로 딥러닝 모형 개발 가능

- 생성적 적대 신경망(GAN : Generative Adversarial Networks)

  > GAN은 두 개의 인공신경망으로 구성된 딥러닝 이미지 생성 알고리즘

  - 생성자가 가짜 사례를 생성하면 감별자가 진위를 판별하도록 구성한 후 이들이 적대적 관계 속에서 공방전을 반복하도록 함
    - 가짜 사례의 정밀도를 점점 더 진짜 사례와 구별하기 어려운 수준으로 높이는 방식으로 작동
  - 주로 새로운 합성 이미지를 생성하는 분석에 많이 적용되어 왔으나, 점차 다른 분야에 응용하는 사례가 늘고 있음

- 오토인코더

  > 오토인코더는 라벨이 설정되어 있지 않은 학습 데이터로부터 더욱 효율적인 코드로 표현하도록 학습하는 신경망

  - 입력 데이터의 차원을 줄여 모형을 단순화시키기 위해 활용할 수 있음

- 설명 가능한 인공지능(XAI : eXplainable AI)

  > 설명 가능한 인공지능은 **결론 도출 과정에 대한 근거를 차트나 수치 또는 자연어 형태의 설명으로 제공**

  - 기존의 기계학습은 정확한 예측을 할 수 있도록 하는 방향으로 개발되어 옴
    - 기존 기계학습의 완성된 모형은 내부 구조가 매우 복잡하고 의미를 이해하기 어려워 일종의 블랙박스 모형이라 불림

- 기계학습 자동화

  > 기계학습 자동화는 명칭 그대로 기계학습의 전체 과정을 자동화하는 것

  - 세부적으로는 데이터 전처리, 변수 생성, 변수 선택, 알고리즘 선택, 하이퍼파라미터 최적화 등의 기능 수행
  - 기계학습 모형 개발 과정의 생산성을 높이며 비전문가들의 활용을 용이하게 할 것으로 기대

### 5) 인공지능의 한계점과 발전방향

- 국내시장의 한계
  - 국내에서 축적한 머신러닝 및 인공지능과 관련한 수학, 통계학적 이해도는 낮은 수준
  - 인공지능 개발을 위한 데이터 확보 및 그 중요성에 대한 인식이 부족
- 인공지능의 미래
  - 딥러닝의 재학습 및 전이학습 특성을 활용한 사전학습모형이 새로운 데이터 경제의 모습이 될 것
    - 데이터 경제는 수집, 학습용 데이터로의 가공, 전이학습용 사전학습 모형으로 구분되고 있음
  - 마스킹이나 라벨링 등의 애노테이션 작업을 통해 학승용 데이터를 가공하는 산업이 확산되고 있음
  - 복잡한 BERT의 학습을 위한 구글의 클라우드 서비스와 같은 확장된 개념의 데이터 경제로 파생될 것으로 보임







## 4. 개인정보 개요

### 1) 개인정보의 정의와 판단기준

- 개인정보의 정의
  - **<u>살아 있는 개인에 관한 정보</u>**로서 개인을 알아볼 수 있는 정보
  - 해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 정보를 포함
- 개인정보 판단기준
  - '생존하는' '개인에 관한' 정보여야 함
  - '정보'의 내용, 형태 등은 제한이 없음
  - 개인을 '알아볼 수 있는' 정보여야 함
    - 다른 정보와 '쉽게 결합하여' 개인을 알아볼 수 있는 정보도 포함
- 개인정보의 예
  - 성명, 전화번호, 주소, 주민등록번호, 운전면허번호, 학번 또는 회사의 사번 등

### 2) 개인정보의 처리와 활용

- 개인정보의 이전

  > 개인정보가 다른 사람에게 이전되거나 공동으로 처리하게 하는 것

- 개인정보의 처리 위탁

  > 개인정보처리자의 업무를 처리할 목적으로 제3자에게 이전되는 것
  >
  > 개인정보를 **<u>제공하는 자</u>**의 업무 처리와 이익을 위하는 경우

- 개인정보의 제3자 제공

  > 해당 정보를 제공받는 자의 고유한 업무를 처리할 목적 및 이익을 위하여 개인정보가 이전되는 것
  >
  > 개인정보를 **<u>제공받는 자</u>**의 업무 처리와 이익을 위하는 경우

### 3) 개인정보의 보호

- 개인정보의 보호조치

  - 조직 내부의 정보보안 방침과 개인정보보호법에 위배되지 않도록 개인정보보호 가이드라인 점검
  - 데이터를 외부에 공개하는 경우 가이드라인에서 정한 규칙을 준수하는지 반드시 확인
  - 가이드라인에 명시되지 않은 경우 관계기관이나 조직 내부의 법무가이드를 받은 후 적절한 범위 안에서 데이터 활용
  - 개인정보 보호를 위해 주기적인 패스워드 변경, 시스템 패스워드 관리 보안 강화, 정기적인 보안교육 참여 등 유도
  - 백신의 설치 및 최신버전 유지, 개인정보를 과하게 요구하는 사이트의 가입을 자제

- 빅데이터 개인정보보호 가이드라인(방통위)

  <img src="https://user-images.githubusercontent.com/87686562/147875491-2f622542-03be-486f-9a51-d9a757924493.jpg" alt="2-7" style="zoom:20%;" />



## 5. 개인정보 법, 제도

### 1) 개인정보보호법

> 개인정보 보호를 위한 법체계를 일원화하고 개인의 권익 보호를 강화하기 위한 법

- 개인정보보호법의 개요

  - **<u>당사자의 동의 없는 개인정보 수집 및 활용하거나 제3자에게 제공하는 것을 금지</u>**하는 등 개인정보보호를 강화한 내용을 담아 제정한 법률
  - 상대방의 동의 없이 개인정보를 제3자에게 제공하면 5년 이하의 징역이나 5000만 원 이하의 벌금에 처함

- 개인정보의 범위(제2조 제1호)

  > 광범위한 데이터가 개인정보에 해당하여 이 법이 적용될 수 있다는 점을 유의해야 함

  - 어떤 정보가 개인정보에 해당하는지는 그 정보가 특정 개인을 알아볼 수 있게 하는 다른 정보와 쉽게 결합할 수 있는가에 따라 결정
  - 법원은 그 정보 자체로는 누구의 정보인지를 알 수 없더라도 다른 정보와 결합 가능성을 비교적 넓게 인정

- 개인정보의 처리 위탁

  ```
  - 일정한 내용을 기재한 문서에 의하여 업무 위탁이 이루어져야 함
  - 위탁하는 업무의 내용과 수탁자를 정보주체에게 알려야 하는바, 개인정보 처리방침에 해당 내용을 추가하여 공개하거나,
    사업장 등의 보기 쉬운 장소에 게시하는 방법 등을 시행해야 함
  - 수탁자에 대한 교육 및 감독 의무를 부담하게 됨
  - 수탁자가 위탁 받은 업무와 관련하여 개인정보를 처리하는 과정에서 개인정보보호법을 위반하여 발생한
    손해배상책임에 대하여는 수탁자를 개인정보처리자의 소속 직원으로 봄
  - 손해가 발생한 경우 정보주체의 손해배상 청구에 대해 위탁자가 책임을 질 수 있음
  ```

- 개인정보의 제3자 제공

  - 정보주체로부터 개인정보 제3자 제공 동의를 받아야 함

- 개인정보 처리 위탁과 제3자 제공 판단 기준

  > 서울중앙지법 2018.08.16 선고 2017노1296 판결

  - 개인정보의 취득목적과 방법
  - 대가 수수 여부
  - 수탁자에 대한 실질적인 관리, 감독 여부
  - 정보주체 또는 이용자의 개인정보 보호 필요성에 미치는 영향
  - 개인정보를 이용할 필요가 있는 자가 실질적으로 누구인지 등

### 2) 정보통신망 이용촉진 및 정보보호 등에 관한 법률(정보통신망법)

- 정보통신망법의 개요

  - **<u>정보통신망의 개발과 보급 등 이용 촉진과 함께 통신망을 통해 활용되고 있는 정보보호에 관해 규정</u>**한 법률
  - 이용자의 동의를 받지 않고 개인정보를 수집하거나 제3자에게 개인정보를 제공한 경우
  - 법정 대리인의 동의 없이 만 14세 미만의 아동의 개인정보를 수집한 경우
  - 악성프로그램을 전달 또는 유포한 경우 등 5년 이하 징역 또는 5000만 원 이하의 벌금

- 개인정보의 처리 위탁

  ```
  - 원칙적으로는 개인정보 처리위탁을 받는 자, 개인정보 처리위탁을 하는 업무의 내용을 이용자에게 알리고 동의를 받아야 함
  - 단, 정보통신서비스 제공자 등은 정보통신서비스의 제공에 관한 계약을 이행하고 이용자의 편의 증진 등을 위하여 필요한 경우
    고지절차와 동의절차를 거치지 않고, 이용자에게 이에 관해 알리거나 개인정보 처리방침 등에 이를 공개할 수 있다
  - 만일 제3자에게 데이터 분석을 위탁할 경우, 해당 서비스가 정보통신서비스 제공에 관한 계약을 이행하고
    이용자의 편의 증진을 위한 것인지 검토해야 한다.
  ```

### 3) 신용정보의 이용 및 보호에 관한 법률(신용정보보호법)

- 신용정보보호법의 개요

  ```
  - 개인신용정보를 신용정보회사 등에게 제공하고자 하는 경우에 해당 개인으로부터 서면 또는 공인전자서명이 있는
    전자문서에 의한 동의 등을 얻어야 한다.
  - 신용정보주체는 신용정보회사 등이 본인에 관한 신용정보를 제공하는 때에는
    제공받은 자, 그 이용 목적, 제공한 본인정보의 주요 내용 등을 통보하도록 요구하거나
    인터넷을 통하여 조회할 수 있도록 요구할 수 있다.
  - 신용정보회사 등이 보유하고 있는 본인정보의 제공 또는 열람을 청구할 수 있고,
    사실과 다른 경우네는 정정을 요청할 수 있다.
  ```

- 개인정보의 범위

  > '신용정보'란 금융거래 등 상거래에 있어서 거래 상대방의 신용을 판단할 때 필요한 정보

  ```
  1. 특정 신용정보주체를 식별할 수 있는 정보
  2. 신용정보주체의 거래내용을 판단할 수 있는 정보
  3. 신용정보주체의 신용도를 판단할 수 있는 정보
  4. 신용정보주체의 신용거래능력을 판단할 수 있는 정보
  5. 그 밖에 1번부터 4번까지와 유사한 정보
  ```

- 개인신용정보

  ```
  금융거래 등 상거래에 있어서 거래 상대방에 대한 신용도, 신용거래능력 등의 판단을 위해
  필요로 하는 정보로 정의하고, 그 세부 사항은 대통령령으로 정함
  ```


- 개인신용정보의 처리 위탁

  ```
  - 신용정보회사 등은 그 업무 범위에서 의뢰인의 동의를 받아 다른 신용정보회사에 신용정보의 수집, 조사를 위탁할 수 있음
  - 신용정보회사, 신용정보집중기관, 은행, 금융지주회사, 금융투자업자, 보험회사 등은
    신용정보 처리 위탁 시 금융위원회에 보고해야 하며, 이에 관한 구체적 사항은
    '금융회사의 정보처리 업무 위탁에 관한 규정'에 따름
  - 특정 신용정보주체를 식별할 수 있는 정보는 암호화하거나 봉함 등의 보호조치를 하여야 하며,
    신용정보가 분실, 도난, 유출, 변조 또는 훼손당하지 않도록 수탁자를 연 1회 이상 교육하여야 함
  - 위탁계약의 이행에 필요한 경우로서 수집된 신용정보의 처리를 위탁하기 위하여 제공하는 경우
    정보주체의 동의를 받지 않아도 됨
  ```

- 개인신용정보의 제3자 제공

  ```
  - 개인신용정보를 타인에게 제공하려는 경우
    정보주체에 서비스 제공을 위하여 필수적 동의 사항과 그 밖의 선택적 동의 사항을 구분하여
    설명한 후 각각 동의를 받도록 하고 있음
  - 기타 개인정보 제공 시 개인정보보호법이 적용됨
  ```

### 4) 2020년 데이터 3법의 주요 개정 내용

```
- 데이터 이용 활성화를 위한 '가명정보'개념 도입 및 데이터간 결합 근거 마련
- 개인정보보호 관련 법률의 유사, 중복 규정을 정비 및 거버넌스 체계 효율화
- 데이터 활용에 따른 개인정보처리자 책임 강화
- 다소 모호했던 개인정보의 판단기준 명확화
```

- 개인정보보호법 주요 개정 내용

  ```
  - 개인정보 관련 개념을 개인정보, 가명정보, 익명정보로 구분
  - 가명정보를 통계 작성 연구, 공익적 기록보존 목적을 처리할 수 있도록 허용
  - 가명정보 이용 시 안전장치 및 통제 수단 마련
  - 분산된 개인정보보호 감독기관을 개인정보보호위원회로 일원화
  - 개인정보보호위원회는 국무총리 소속 중앙행정기관으로 격상
  ```

- 정보통신망법 주요 개정 내용

  - 개인정보보호 관련 사항을 개인정보보호법으로 이관
  - 온라인상 개인정보보호 관련 규제 및 감독 주체를 개인정보보호위원회로 변경

- 신용정보보호법 주요 개정 내용

  - 가명정보 개념을 도입해 빅데이터 분석 및 이용의 법적 근거 마련
  - 가명정보는 통계작성, 연구, 공익적 기록보존 등을 위해 신용정보 주체의 동의 없이 이용, 제공 가능



## 6. 개인정보 비식별화

### 1) 개인정보 비식별화의 개요

- 비식별 정보
  - 정보의 집합물에 대해 '개인정보 비식별 조치 가이드라인'에 따라 적정하게 '비식별 조치'된 정보를 말함
- 비식별 조치
  - 정보의 집합물에서 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제
  - 또는 대체 등의 방법을 통해 **<u>개인을 알아볼 수 없도록 하는 조치</u>**를 말함
- 비식별 정보의 활용
  - 비식별 정보는 개인정보가 아닌 정보로 추정되므로 정보주체로부터 별도 동의없이 해당 정보를 이용하거나 제3자에게 제공할 수 있음
    - 다만, 불특정 다수에게 공개되는 경우에는 다른 정보를 보유하고 있는 누군가에 의해 해당 정보주체가 식별될 가능성이 있음
    - 그리하여, 비식별 정보의 공개는 원칙적으로 금지됨

- 비식별 정보의 보호
  - 비식별 정보는 개인정보가 아닌 것으로 추정되지만, 새로운 결합 기술이 나타나거나
  - 결합 가능한 정보가 증가하는 경우에는 정보주체가 '재식별'될 가능성이 있음
  - 비식별 정보를 처리하는 자(비식별 정보를 제공받은 자 포함)가 해당 정보를 이용하는 과정에서
  - 재식별하게 된 경우에는 해당 정보를 즉시 처리중지하고 파기하여야 함
  - 비식별 정보라고 하더라도 필수적인 관리적, 기술적 보호조치는 이행해야 함

### 2) 개인정보 비식별화 조치 가이드라인

- 개인정보 비식별화 조치 가이드라인의 추진배경

  - 정부 3.0 및 빅데이터 활용 확산에 따른 데이터 활용가치가 증대되고 있음
  - 개인정보 보호 강화에 대한 사회적 요구가 지속되고 있음
  - '보호와 활용'을 동시에 모색하는 세계적 정책변화에 적극 대응이 필요함

- 개인정보 비식별화 조치 가이드라인의 단계별 조치사항

  | 단계        | 조치사항                                                     | 데이터                           |
  | ----------- | ------------------------------------------------------------ | -------------------------------- |
  | 사전 검토   | 개인정보에 해당하는지 여부를 검토한 후,<br />개인정보가 아닌 것이 명백한 경우 법적 규제 없이 자유롭게 활용 | 개인정보, 식별정보               |
  | 비식별 조치 | 정보 집합물(데이터 셋)에서 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제하거나<br />대체하는 등의 방법을 활용, 개인을 알아볼 수 없도록 하는 조치 | 가명, 총계, 삭제, 범주화, 마스킹 |
  | 적정성 평가 | 다른 정보와 쉽게 결합하여 개인을 식별할 수 있는지를<br />'비식별 조치 적정성 평가단'을 통해 평가 | k-익명성, l-다양성, t-근접성     |
  | 사후 관리   | 비식별 정보 안전조치, 재식별 가능성 모니터링 등<br />비식별 정보 활용 과정에서 재식별 방지를 위해 필요한 조치 수행 | 관리적/기술적 보호조치           |

<img src="https://user-images.githubusercontent.com/87686562/147877277-5f5d0f8c-3eb6-4fbc-8e93-5deb79192a67.jpg" alt="2-8" style="zoom:15%;" />

- 개인정보 비식별화 조치 가이드라인의 조치방법

<img src="https://user-images.githubusercontent.com/87686562/147877640-9f325ae5-08e0-4a1c-895b-2568de7871d0.PNG" alt="2-9" style="zoom:100%;" />



## 7. 개인정보 활용

### 1) 데이터 수집의 위기 요인과 통제 방안

- 사생활 침해로 위기 발생

  > 사생활 침해 우려는 민간 뿐만이 아닌 정부의 정보 수집에서도 나타나고 있음

  - M2M(Machine to Machine) 시대가 되면서 정보를 수집하는 센서들의 수가 증가하고 있음
  - 개인정보의 가치가 커짐에 따라 많은 사업자들이 개인정보 습득에 더 많은 자원을 투입하고 있음
  - 특정 데이터가 본래 목적 위로 가공되어 2차, 3차 목적으로 활용될 가능성이 커지고 있음
  - 위험의 범위가 사생활 침해 수준을 넘어 사회, 경제적 위협으로 더 확대될 수 있음

- 동의에서 책임으로 강화하여 통제

  - 개인정보는 본래의 1차적 목적 외에도 2차, 3차적 목적으로 가공, 유통, 활용되고 있음
    - 개인정보의 활용에 대해 개인이 매번 동의하는 것은 매우 어려운 일이며, 경제적으로도 비효율적
  - 개인정보 사용으로 발생하는 피해에 대해서는 개인정보 사용자가 책임을 지게 함
  - 개인정보를 사용하는 주체가 익명화 기술 같은 더 적극적인 보호 장치를 마련하게 하는 효과가 있을 것으로 기대됨
    - 익명화 :  사생활 침해를 방지하기 위해 데이터에 포함된 개인정보를 삭제하거나 알아볼 수 없는 형태로 변환하는 방법

### 2) 데이터 활용의 위기 요인과 통제 방안

- 책임원칙 훼손으로 위기 발생

  - 빅데이터의 분석 결과에 따라 특정한 행위를 할 가능성이 높다는 이유만으로

    특정인이 처벌받는 것은 민주주의 사회 원칙을 훼손한다

  - 특정인이 특정한 사회, 경제적 특성을 가진 집단에 속한다는 이유만으로

    그의 신용도와 무관하게 대출이 거절되는 상황은 잘못된 클러스터링의 피해이다

- 결과 기반 책임 원칙을 고수하여 통제

  - 기존의 책임 원칙을 더 강화해야 함
  - 예측 결과에 의해 불이익을 당할 가능성을 최소화하는 방안 마련이 필요함
  - 제도 마련과 함께 알고리즘의 기술적 완성도를 더 높여야 함

### 3) 데이터 처리의 위기 요인과 통제 방안

- 데이터 오용으로 위기 발생

  > 잘못된 인사이트를 도출하여 비즈니스에 활용할 경우 더 많은 손실이 발생할 수 있음

  - **<u>빅데이터는 과거에 일어났던 일로 인해 기록된 데이터에 의존</u>**

    - 빅데이터를 기반으로 미래를 예측하는 것은 어느 정도 정확도를 가질 수 있지만

      항상 맞는 것은 아니다.

  - 빅데이터 사용자가 데이터를 과신할 때 큰 문제가 발생할 가능성이 높다

    - 잘못된 지표를 사용하는 것은 오히려 과거 경험에 의존하는 것보다 더 잘못된 결론을 도출할 수 있음

- 알고리즘 접근을 혀용하여 통제

  - 알고리즘에 대한 접근권한을 부여받아 직접 검증할 수 있도록 함
  - 알고리즘에 대한 객관적인 인증방안을 마련 및 도입
  - 알고리즘의 부당함을 반증할 수 있는 방법을 제시해 줄 것을 요청
  - 공개해 준 알고리즘을 해석해 줄 알고리즈미스트와 같은 전문가 영입
    - 알고리즈미스트는 컴퓨터, 수학, 통계학, 비즈니스 등의 다양한 지식이 필요
